{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# DL HW2\n",
        " - Pretrained Models\n",
        "\n",
        "In this assignment, you will analyze and compare a few pre-trained models from the field of computer vision.\n",
        "\n",
        "The assignment is divided into several tasks:\n",
        "\n",
        "- **EX1 - The Imagenette Dataset (10 pts)**  \n",
        "- **EX2 - Pretrained Models (20 pts)**  \n",
        "- **EX3 - Visualizing Feature Maps (30 pts)**  \n",
        "- **EX4 - K-Nearest Neighbors (KNN) in the Embedding Space (50 pts)**  \n",
        "\n",
        "Note: In this assignment, you will not train any models or aim to reach specific accuracy levels. Instead, you will investigate the behavior of a few pre-trained models.\n",
        "\n",
        "---\n",
        "\n",
        "## Grading\n",
        "\n",
        "The grading for each section is indicated in the title. Grading will be based on the following criteria:\n",
        "\n",
        "- **Following Instructions**  \n",
        "- **Presentation**: Clear figures (with labels, titles, etc.), well-written discussions and comments, organized notebook, no leftover debugging prints, and no redundant functions.  \n",
        "- **Clear and Efficient Code**: Your code should be clear and neat. Write clear comments and avoid `for loops` when vectorized operations are available. Use the GPU when possible.  \n",
        "- **Discussion**: Ensure you write a discussion whenever it is required.  \n",
        "\n",
        "---\n",
        "\n",
        "Submit the fully executed notebook.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "WN-7dc8JIa_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX1 - Imagenette (Small subset of ImageNet) Dataset (10pts)\n",
        "\n",
        "\n",
        "\n",
        "1.   Download the ```Imagenette``` dataset from ```torchvision``` ([link](https://pytorch.org/vision/0.19/generated/torchvision.datasets.Imagenette.html#torchvision.datasets.Imagenette)). Make sure the set size=\"160px\" to avoid long downloading time.\n",
        "2. Preprocess the data - resize to 256x256 and take a central crop of size 224. ToTensor, Normalize and so on.\n",
        "3. Describe the dataset: number of samples for each set, classes labels, classes labels distribtuion (are they balanced?)\n",
        "\n",
        "4. Plot 5 random samples from each class a present them in a ```num_classes X 5``` (rows X columns) grid.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W_gp7AOH8rpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchinfo"
      ],
      "metadata": {
        "id": "cCYTnj6fBXrP",
        "outputId": "52fbda3d-de72-48d9-e65e-d4530f1fb737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Imports ###\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchinfo import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7h7QpwUZIqcN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Preprocessing ###\n",
        "\n",
        "# We will use the known mean and std of the ImageNet dataset for normalization\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "imagenette_train = datasets.Imagenette(\n",
        "    download=True,\n",
        "    root=\"./data\",\n",
        "    size=\"160px\",\n",
        "    split=\"train\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "imagenette_val = datasets.Imagenette(\n",
        "    download=True,\n",
        "    root=\"./data\",\n",
        "    size=\"160px\",\n",
        "    split=\"val\",\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "cNx2Bkf2RIss"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Description ###\n",
        "\n",
        "# Number of samples for each set\n",
        "print(\"Number of train samples: \", len(imagenette_train))\n",
        "print(\"Number of validation samples: \", len(imagenette_val))\n",
        "\n",
        "# Class labels\n",
        "label_names = [cls[0] for cls in imagenette_train.classes]\n",
        "print(f\"\\nClass labels: {label_names}\\n\")\n",
        "\n",
        "# Class labels distribution\n",
        "labels = [label for _, label in imagenette_train]\n",
        "_, counts = np.unique(labels, return_counts=True)\n",
        "label_counts = dict(zip(label_names, counts.data))\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.bar(label_counts.keys(), label_counts.values(), width=0.3)\n",
        "plt.title(\"Class labels distribution (train)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lOGIc2oMQ4PT",
        "outputId": "c38a1fca-6c5e-4787-e33d-fc18bc7f13b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples:  9469\n",
            "Number of validation samples:  3925\n",
            "\n",
            "Class labels: ['tench', 'English springer', 'cassette player', 'chain saw', 'church', 'French horn', 'garbage truck', 'gas pump', 'golf ball', 'parachute']\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot shows the number of samples from each class is similar, the only one that stands out to us is chain saw which is lower than the others but not by that much(relatively), so we think the classes are balanced."
      ],
      "metadata": {
        "id": "pzWhgk5l7j1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX2 - Pretrained models (20pts)\n",
        "\n",
        "1. Choose 2 models from ```torchvision.models``` ([link](https://pytorch.org/vision/stable/models.html)) that were pretrained on ImageNet. The third model is one of ResNet18/34/50 (the other models can't other ResNet variation).\n",
        "2. Use ```torch-summary``` to summarize each model for an input of shape ```1x3x224x224```.\n",
        "3. Describe each model in 2-4 lines. Think carefully what information might be relevant for this homework assignment (see EX3-EX4). It is recommended to read the paper in which each model was first presented but it is not required. You are, however, required to go over model's description in torchvision documentation (see the information tab for ResNet18 for an example [link](https://pytorch.org/vision/0.19/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18) )\n",
        "4. Summarize the similarities and difference between the 3 models."
      ],
      "metadata": {
        "id": "yDdQGME1-Swl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvNext-Tiny"
      ],
      "metadata": {
        "id": "eu43_AyPR-sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ConvNext-Tiny Summary ###\n",
        "\n",
        "summary(models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1), input_size=(1, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"kernel_size\", \"num_params\"])\n"
      ],
      "metadata": {
        "id": "SNuxIeqY7hnN",
        "outputId": "42e61a9e-a762-43e3-ca5b-6a40ffe19124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Kernel Shape              Param #\n",
              "=================================================================================================================================================\n",
              "ConvNeXt                                      [1, 3, 224, 224]          [1, 1000]                 --                        --\n",
              "├─Sequential: 1-1                             [1, 3, 224, 224]          [1, 768, 7, 7]            --                        --\n",
              "│    └─Conv2dNormActivation: 2-1              [1, 3, 224, 224]          [1, 96, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-1                       [1, 3, 224, 224]          [1, 96, 56, 56]           [4, 4]                    4,704\n",
              "│    │    └─LayerNorm2d: 3-2                  [1, 96, 56, 56]           [1, 96, 56, 56]           --                        192\n",
              "│    └─Sequential: 2-2                        [1, 96, 56, 56]           [1, 96, 56, 56]           --                        --\n",
              "│    │    └─CNBlock: 3-3                      [1, 96, 56, 56]           [1, 96, 56, 56]           --                        79,296\n",
              "│    │    └─CNBlock: 3-4                      [1, 96, 56, 56]           [1, 96, 56, 56]           --                        79,296\n",
              "│    │    └─CNBlock: 3-5                      [1, 96, 56, 56]           [1, 96, 56, 56]           --                        79,296\n",
              "│    └─Sequential: 2-3                        [1, 96, 56, 56]           [1, 192, 28, 28]          --                        --\n",
              "│    │    └─LayerNorm2d: 3-6                  [1, 96, 56, 56]           [1, 96, 56, 56]           --                        192\n",
              "│    │    └─Conv2d: 3-7                       [1, 96, 56, 56]           [1, 192, 28, 28]          [2, 2]                    73,920\n",
              "│    └─Sequential: 2-4                        [1, 192, 28, 28]          [1, 192, 28, 28]          --                        --\n",
              "│    │    └─CNBlock: 3-8                      [1, 192, 28, 28]          [1, 192, 28, 28]          --                        306,048\n",
              "│    │    └─CNBlock: 3-9                      [1, 192, 28, 28]          [1, 192, 28, 28]          --                        306,048\n",
              "│    │    └─CNBlock: 3-10                     [1, 192, 28, 28]          [1, 192, 28, 28]          --                        306,048\n",
              "│    └─Sequential: 2-5                        [1, 192, 28, 28]          [1, 384, 14, 14]          --                        --\n",
              "│    │    └─LayerNorm2d: 3-11                 [1, 192, 28, 28]          [1, 192, 28, 28]          --                        384\n",
              "│    │    └─Conv2d: 3-12                      [1, 192, 28, 28]          [1, 384, 14, 14]          [2, 2]                    295,296\n",
              "│    └─Sequential: 2-6                        [1, 384, 14, 14]          [1, 384, 14, 14]          --                        --\n",
              "│    │    └─CNBlock: 3-13                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-14                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-15                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-16                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-17                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-18                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-19                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-20                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    │    └─CNBlock: 3-21                     [1, 384, 14, 14]          [1, 384, 14, 14]          --                        1,201,920\n",
              "│    └─Sequential: 2-7                        [1, 384, 14, 14]          [1, 768, 7, 7]            --                        --\n",
              "│    │    └─LayerNorm2d: 3-22                 [1, 384, 14, 14]          [1, 384, 14, 14]          --                        768\n",
              "│    │    └─Conv2d: 3-23                      [1, 384, 14, 14]          [1, 768, 7, 7]            [2, 2]                    1,180,416\n",
              "│    └─Sequential: 2-8                        [1, 768, 7, 7]            [1, 768, 7, 7]            --                        --\n",
              "│    │    └─CNBlock: 3-24                     [1, 768, 7, 7]            [1, 768, 7, 7]            --                        4,763,136\n",
              "│    │    └─CNBlock: 3-25                     [1, 768, 7, 7]            [1, 768, 7, 7]            --                        4,763,136\n",
              "│    │    └─CNBlock: 3-26                     [1, 768, 7, 7]            [1, 768, 7, 7]            --                        4,763,136\n",
              "├─AdaptiveAvgPool2d: 1-2                      [1, 768, 7, 7]            [1, 768, 1, 1]            --                        --\n",
              "├─Sequential: 1-3                             [1, 768, 1, 1]            [1, 1000]                 --                        --\n",
              "│    └─LayerNorm2d: 2-9                       [1, 768, 1, 1]            [1, 768, 1, 1]            --                        1,536\n",
              "│    └─Flatten: 2-10                          [1, 768, 1, 1]            [1, 768]                  --                        --\n",
              "│    └─Linear: 2-11                           [1, 768]                  [1, 1000]                 --                        769,000\n",
              "=================================================================================================================================================\n",
              "Total params: 28,589,128\n",
              "Trainable params: 28,589,128\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 322.37\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 131.27\n",
              "Params size (MB): 114.33\n",
              "Estimated Total Size (MB): 246.21\n",
              "================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description\n",
        "ConvNext-Tiny uses Conv2d layers for downsampling, going from 96x56x56 to 192x28x28 to 384x14x14 to a final feature map of 768x7x7, and a final flattened embedding vector of size 768 after global average pooling.\n",
        "Between the downampling convolutions there are LayerNorms and ConvNext blocks which are composed of 7x7 depthwise convolutions and 2 Linear layers."
      ],
      "metadata": {
        "id": "d3BPQoP-MioP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VisionTransformer"
      ],
      "metadata": {
        "id": "fPzAqXN7SNb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ViT-B/16 Summary ###\n",
        "\n",
        "summary(models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1), input_size=(1, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"kernel_size\", \"num_params\"])"
      ],
      "metadata": {
        "id": "Z4G2EONgQazn",
        "outputId": "f082e50f-b237-4452-e14d-b9df92b5ac60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape               Output Shape              Kernel Shape              Param #\n",
              "=================================================================================================================================================\n",
              "VisionTransformer                             [1, 3, 224, 224]          [1, 1000]                 --                        768\n",
              "├─Conv2d: 1-1                                 [1, 3, 224, 224]          [1, 768, 14, 14]          [16, 16]                  590,592\n",
              "├─Encoder: 1-2                                [1, 197, 768]             [1, 197, 768]             --                        151,296\n",
              "│    └─Dropout: 2-1                           [1, 197, 768]             [1, 197, 768]             --                        --\n",
              "│    └─Sequential: 2-2                        [1, 197, 768]             [1, 197, 768]             --                        --\n",
              "│    │    └─EncoderBlock: 3-1                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-2                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-3                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-4                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-5                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-6                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-7                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-8                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-9                 [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-10                [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-11                [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    │    └─EncoderBlock: 3-12                [1, 197, 768]             [1, 197, 768]             --                        7,087,872\n",
              "│    └─LayerNorm: 2-3                         [1, 197, 768]             [1, 197, 768]             --                        1,536\n",
              "├─Sequential: 1-3                             [1, 768]                  [1, 1000]                 --                        --\n",
              "│    └─Linear: 2-4                            [1, 768]                  [1, 1000]                 --                        769,000\n",
              "=================================================================================================================================================\n",
              "Total params: 86,567,656\n",
              "Trainable params: 86,567,656\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 173.23\n",
              "=================================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 104.09\n",
              "Params size (MB): 232.27\n",
              "Estimated Total Size (MB): 336.96\n",
              "================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description\n",
        "ViT-B/16 uses a 16x16 convolution with 16 stride to split the input image into 16x16 patches, then transforms each patch into tokens of size 768. The 196 tokens are grouped with a cls token in a 197x768 matrix. This matrix is passed as input to 12 Transformer Encoder blocks which are composed of Nomalization, Multi-Head Self-Attention, and 2 Linear layers, and keep the dimensions the same. Classification is done at the end using a Linear layer with the learned cls token as the embedding."
      ],
      "metadata": {
        "id": "0TCNKQchSXqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet18"
      ],
      "metadata": {
        "id": "nkBZchySs_QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ResNet18 Summary ###\n",
        "\n",
        "summary(models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1), input_size=(1, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"kernel_size\", \"num_params\"], depth=4)"
      ],
      "metadata": {
        "id": "2LxECb26tCmD",
        "outputId": "74365200-0976-4473-bfc6-830a8e67e964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape              Param #\n",
              "============================================================================================================================================\n",
              "ResNet                                   [1, 3, 224, 224]          [1, 1000]                 --                        --\n",
              "├─Conv2d: 1-1                            [1, 3, 224, 224]          [1, 64, 112, 112]         [7, 7]                    9,408\n",
              "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         [1, 64, 112, 112]         --                        128\n",
              "├─ReLU: 1-3                              [1, 64, 112, 112]         [1, 64, 112, 112]         --                        --\n",
              "├─MaxPool2d: 1-4                         [1, 64, 112, 112]         [1, 64, 56, 56]           3                         --\n",
              "├─Sequential: 1-5                        [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           [1, 64, 56, 56]           [3, 3]                    36,864\n",
              "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           [1, 64, 56, 56]           --                        128\n",
              "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           [1, 64, 56, 56]           [3, 3]                    36,864\n",
              "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           [1, 64, 56, 56]           --                        128\n",
              "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           [1, 64, 56, 56]           [3, 3]                    36,864\n",
              "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           [1, 64, 56, 56]           --                        128\n",
              "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           [1, 64, 56, 56]           [3, 3]                    36,864\n",
              "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           [1, 64, 56, 56]           --                        128\n",
              "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "├─Sequential: 1-6                        [1, 64, 56, 56]           [1, 128, 28, 28]          --                        --\n",
              "│    └─BasicBlock: 2-3                   [1, 64, 56, 56]           [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-13                 [1, 64, 56, 56]           [1, 128, 28, 28]          [3, 3]                    73,728\n",
              "│    │    └─BatchNorm2d: 3-14            [1, 128, 28, 28]          [1, 128, 28, 28]          --                        256\n",
              "│    │    └─ReLU: 3-15                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-16                 [1, 128, 28, 28]          [1, 128, 28, 28]          [3, 3]                    147,456\n",
              "│    │    └─BatchNorm2d: 3-17            [1, 128, 28, 28]          [1, 128, 28, 28]          --                        256\n",
              "│    │    └─Sequential: 3-18             [1, 64, 56, 56]           [1, 128, 28, 28]          --                        --\n",
              "│    │    │    └─Conv2d: 4-1             [1, 64, 56, 56]           [1, 128, 28, 28]          [1, 1]                    8,192\n",
              "│    │    │    └─BatchNorm2d: 4-2        [1, 128, 28, 28]          [1, 128, 28, 28]          --                        256\n",
              "│    │    └─ReLU: 3-19                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-20                 [1, 128, 28, 28]          [1, 128, 28, 28]          [3, 3]                    147,456\n",
              "│    │    └─BatchNorm2d: 3-21            [1, 128, 28, 28]          [1, 128, 28, 28]          --                        256\n",
              "│    │    └─ReLU: 3-22                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-23                 [1, 128, 28, 28]          [1, 128, 28, 28]          [3, 3]                    147,456\n",
              "│    │    └─BatchNorm2d: 3-24            [1, 128, 28, 28]          [1, 128, 28, 28]          --                        256\n",
              "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "├─Sequential: 1-7                        [1, 128, 28, 28]          [1, 256, 14, 14]          --                        --\n",
              "│    └─BasicBlock: 2-5                   [1, 128, 28, 28]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-26                 [1, 128, 28, 28]          [1, 256, 14, 14]          [3, 3]                    294,912\n",
              "│    │    └─BatchNorm2d: 3-27            [1, 256, 14, 14]          [1, 256, 14, 14]          --                        512\n",
              "│    │    └─ReLU: 3-28                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-29                 [1, 256, 14, 14]          [1, 256, 14, 14]          [3, 3]                    589,824\n",
              "│    │    └─BatchNorm2d: 3-30            [1, 256, 14, 14]          [1, 256, 14, 14]          --                        512\n",
              "│    │    └─Sequential: 3-31             [1, 128, 28, 28]          [1, 256, 14, 14]          --                        --\n",
              "│    │    │    └─Conv2d: 4-3             [1, 128, 28, 28]          [1, 256, 14, 14]          [1, 1]                    32,768\n",
              "│    │    │    └─BatchNorm2d: 4-4        [1, 256, 14, 14]          [1, 256, 14, 14]          --                        512\n",
              "│    │    └─ReLU: 3-32                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    └─BasicBlock: 2-6                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-33                 [1, 256, 14, 14]          [1, 256, 14, 14]          [3, 3]                    589,824\n",
              "│    │    └─BatchNorm2d: 3-34            [1, 256, 14, 14]          [1, 256, 14, 14]          --                        512\n",
              "│    │    └─ReLU: 3-35                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-36                 [1, 256, 14, 14]          [1, 256, 14, 14]          [3, 3]                    589,824\n",
              "│    │    └─BatchNorm2d: 3-37            [1, 256, 14, 14]          [1, 256, 14, 14]          --                        512\n",
              "│    │    └─ReLU: 3-38                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "├─Sequential: 1-8                        [1, 256, 14, 14]          [1, 512, 7, 7]            --                        --\n",
              "│    └─BasicBlock: 2-7                   [1, 256, 14, 14]          [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-39                 [1, 256, 14, 14]          [1, 512, 7, 7]            [3, 3]                    1,179,648\n",
              "│    │    └─BatchNorm2d: 3-40            [1, 512, 7, 7]            [1, 512, 7, 7]            --                        1,024\n",
              "│    │    └─ReLU: 3-41                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-42                 [1, 512, 7, 7]            [1, 512, 7, 7]            [3, 3]                    2,359,296\n",
              "│    │    └─BatchNorm2d: 3-43            [1, 512, 7, 7]            [1, 512, 7, 7]            --                        1,024\n",
              "│    │    └─Sequential: 3-44             [1, 256, 14, 14]          [1, 512, 7, 7]            --                        --\n",
              "│    │    │    └─Conv2d: 4-5             [1, 256, 14, 14]          [1, 512, 7, 7]            [1, 1]                    131,072\n",
              "│    │    │    └─BatchNorm2d: 4-6        [1, 512, 7, 7]            [1, 512, 7, 7]            --                        1,024\n",
              "│    │    └─ReLU: 3-45                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    └─BasicBlock: 2-8                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-46                 [1, 512, 7, 7]            [1, 512, 7, 7]            [3, 3]                    2,359,296\n",
              "│    │    └─BatchNorm2d: 3-47            [1, 512, 7, 7]            [1, 512, 7, 7]            --                        1,024\n",
              "│    │    └─ReLU: 3-48                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-49                 [1, 512, 7, 7]            [1, 512, 7, 7]            [3, 3]                    2,359,296\n",
              "│    │    └─BatchNorm2d: 3-50            [1, 512, 7, 7]            [1, 512, 7, 7]            --                        1,024\n",
              "│    │    └─ReLU: 3-51                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 7, 7]            [1, 512, 1, 1]            --                        --\n",
              "├─Linear: 1-10                           [1, 512]                  [1, 1000]                 --                        513,000\n",
              "============================================================================================================================================\n",
              "Total params: 11,689,512\n",
              "Trainable params: 11,689,512\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 1.81\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.75\n",
              "Params size (MB): 46.76\n",
              "Estimated Total Size (MB): 87.11\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description\n",
        "ResNet18 begins with a 7x7 Convolution and continues with 8 BasicBlocks which are composed of 2 groups of 3x3 convolution, BatchNorm and ReLU, sometimes with another 1x1 convolution in the end for downsampling, with skip connections between the blocks. The downsampling ends with a 512x7x7 feature map and after global average pooling we end up with an embedding vector of size 512."
      ],
      "metadata": {
        "id": "BVm9vgbWw_uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model similarities and differences\n",
        "1. Architecture type - ResNet18 and ConvNext-Tiny are CNN's, while ViT-B/16 is a transformer model that uses self-attention layers instead of convolutional layers\n",
        "2. Embeddings - All 3 models produce an embedding vector in the end and can be used as a backbone for image classification.\n",
        "3. Representation - In the ResNet18 and ConvNext-Tiny architectures each block produces a feature map, while the Vit-B/16 produces a token sequence after each Encoder block.\n",
        "4. Parameters - Vit-B/16 has 86 Million parameters, way more than ResNet18 and ConvNext-Tiny."
      ],
      "metadata": {
        "id": "n2Wl4G0h0_Ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX3 - Visualizing feature maps (30pts)\n",
        "In this section you will visualize the feature maps learned by your chosen models.\n",
        "\n",
        "\n",
        "*   In a convoultion-based models (i.e., ResNet, ConvNext), use the final conv block. If the image resolution is too small do to maxpooling operations, you may choose a different block.\n",
        "*   In a vision transformer (ViT), use model output without the cls token (if relevant).\n",
        "\n",
        "Assignments:\n",
        "\n",
        "\n",
        "1.   Describe the feature map shape for an input image of shape ```1x3x224x224``` (i.e., ```1x512xHxW``` for some model).\n",
        "2. Choose 1 class from Imagenette and sample 10 random images.\n",
        "3. Extract the feature maps from each model and perform PCA on the channel dim and reduce it to 3. The output should be of size ```10x3xHxW```\n",
        "4. Resize the features to 112x112 and plot the images for each model (3 row x 10 columns)\n",
        "5. Summarize the similarities and difference between the 3 models according to the PCA for the features you have presented.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7CbWbGNf_Kbn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JEXI-OMUB7lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EX4 - K-Nearest Neighbors (KNN) in the Embedding Space (50pts)\n",
        "Also know ans \"few-shot/ Zero-shot learning\".\n",
        "Perform KNN classification using the feature vectors from each of the 3 models between the train and test set of Imagenette.\n",
        "\n",
        "\n",
        "## Visualizing the embedding layer distribution.\n",
        "* Write an ```extract_embedding(dataloader, model, model_name)``` function that takes in a dataloader and a model and return the ```N x Num_features``` matrix for that set. Make sure that shuffle is off.\n",
        "* You may write different condition for different models. I.e., the embedding in a ViT model is the ```CLS``` token.\n",
        "\n",
        "* Plot the t-SNE of the train set for each of the 3 models. Color label the points according to the class labels (see t-SNE implementation by sklearn).\n",
        "\n",
        "* Write a 2-3 lines disscussion about the data distribution of each model and their comparison.\n",
        "\n",
        "\n",
        "## Build a KNN ```class``` with the following methods:\n",
        "\n",
        "\n",
        "*   ```init()```: takes the num_classes and other useful information.\n",
        "* ```extract_embedding(X, model)```: Extracts the embedding vector for the entire train set using the model. X_features should be ```Nxnum_ft```. Call the function from the previous section.\n",
        "\n",
        "*   ```fit(X_train, y_train, model)```: Extracts the embedding vector for the entire train set using the ```extract_embedding()``` method and stores it as ```self.X_train_ft``` and ```self.y_labels``` (the labels from the train set).  \n",
        "\n",
        "\n",
        "*   ```predict(X_test, model, n_neighbors)```: Extracts the embedding vector for the entire train set using the ```extract_embedding()``` method and performs KNN for a given K. Returns the predicted_labels.\n",
        "* ```compute_accuracy(y_true, y_pred)```.\n",
        "\n",
        "\n",
        "## Compare the KNN accuracy\n",
        "using each of the 3 models for $K\\in[1,3,5 ]$ and report the results in a table or a graph. Summarize the results in 2-4 lines.\n"
      ],
      "metadata": {
        "id": "VPCKV-Jk_Kd4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kT3GVCx9CHtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}